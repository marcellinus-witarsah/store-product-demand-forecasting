{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add root project directory\n",
    "sys.path.append(\"../\")\n",
    "# get environment path file\n",
    "dotenv_path = dotenv.find_dotenv()\n",
    "# load environment variables\n",
    "dotenv.load_dotenv(dotenv_path)\n",
    "\n",
    "CALENDAR_FILE_PATH = os.environ.get(\"CALENDAR_FILE_PATH\")\n",
    "SALES_TRAIN_EVALUATION_FILE_PATH = os.environ.get(\"SALES_TRAIN_EVALUATION_FILE_PATH\")\n",
    "SALES_TRAIN_VALIDATION_FILE_PATH = os.environ.get(\"SALES_TRAIN_VALIDATION_FILE_PATH\")\n",
    "SAMPLE_SUBMISSION_FILE_PATH = os.environ.get(\"SAMPLE_SUBMISSION_FILE_PATH\")\n",
    "SELL_PRICES_FILE_PATH = os.environ.get(\"SELL_PRICES_FILE_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "calendar = pd.read_csv(CALENDAR_FILE_PATH)\n",
    "sell_price = pd.read_csv(SELL_PRICES_FILE_PATH)\n",
    "sales_train_validation = pd.read_csv(SALES_TRAIN_VALIDATION_FILE_PATH)\n",
    "calendar_ori = calendar.copy()\n",
    "sell_price_ori = sell_price.copy()\n",
    "sales_train_validation_ori = sales_train_validation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
       "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
       "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
       "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
       "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
       "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN          NaN        0        0        0  \n",
       "1          NaN          NaN          NaN        0        0        0  \n",
       "2          NaN          NaN          NaN        0        0        0  \n",
       "3          NaN          NaN          NaN        1        1        0  \n",
       "4          NaN          NaN          NaN        1        0        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price\n",
       "0     CA_1  HOBBIES_1_001     11325        9.58\n",
       "1     CA_1  HOBBIES_1_001     11326        9.58\n",
       "2     CA_1  HOBBIES_1_001     11327        8.26\n",
       "3     CA_1  HOBBIES_1_001     11328        8.26\n",
       "4     CA_1  HOBBIES_1_001     11329        8.26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
       "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "3       0       1       3       7       2  \n",
       "4       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1919 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(calendar.head())\n",
    "display(sell_price.head())\n",
    "display(sales_train_validation.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Baseline Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model\n",
    "1. Calculate the weight for the 12 level of aggregation\n",
    "2. Perform naive forecast on the each of the level\n",
    "3. Infer forecst, ground truth values, and weights for all the higher level series by aggregating\n",
    "4. Calculate RMSSE for all the series\n",
    "5. Multiple the weight to each repective RMSSE and sum it all up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['d'] = calendar_ori['d'].apply(lambda x: x.split('_')[1]).astype(int)\n",
    "sell_price['id'] = sell_price_ori['item_id'] + '_' + sell_price_ori['store_id'] + '_validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate the weight for the 12 level of aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:23<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for day in tqdm(range(1858, 1886)):\n",
    "    wk_id = list(calendar[calendar['d']==day]['wm_yr_wk'])[0]  # select the wm_yr_wk\n",
    "    wk_price_df = sell_price[sell_price['wm_yr_wk']==wk_id]  # filter based on wm_yr_wk\n",
    "    sales_train_validation = sales_train_validation.merge(wk_price_df[['id', 'sell_price']], on=['id'], how='inner')  # merge it with the main transaction data\n",
    "    sales_train_validation['unit_sales_' + str(day)] = sales_train_validation['sell_price'] * sales_train_validation['d_' + str(day)]  # calculate the total sell with the sell price on that specific day\n",
    "    sales_train_validation.drop(columns=['sell_price'], inplace=True)  # drop the sell price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation['dollar_sales'] = sales_train_validation[[c for c in sales_train_validation.columns if c.find(\"unit_sales\")==0]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation.drop(columns=[c for c in sales_train_validation.columns if c.find(\"unit_sales\")==0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation['weight'] = sales_train_validation['dollar_sales'] / sales_train_validation['dollar_sales'].sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation.drop(columns=['dollar_sales'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform naive forecast on the each of the level\n",
    "There are multiple choices such as:\n",
    "- add all 0s to the prediction\n",
    "- average through all the history (**exclude day where the sales is 0**)\n",
    "- same as previous 28 days\n",
    "- mean of pervious 10, 20, 30, 40, 50, 60 days\n",
    "- Average of same day for all previous weeks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using all 0's for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using all 0 for the prediction\n",
    "for d in range(1886, 1914):\n",
    "    sales_train_validation['f_0' + str(d)] = 0\n",
    "\n",
    "method_dict = {0 : \"using all 0s\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete historical average and non zero historical average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical average\n",
    "complete_historical_mean = sales_train_validation[[c for c in sales_train_validation if c.find('d_')==0 and int(c.split('_')[1]) <= 1885]]\\\n",
    "    .mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [00:01<00:00, 18301.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# non_zero_historical_mean = \n",
    "def calc_non_zero_mean(series):\n",
    "    assert type(series) == np.ndarray\n",
    "    return series[series!=0].mean()\n",
    "\n",
    "non_zero_historical_mean = []\n",
    "historical_arr = np.array(sales_train_validation[[c for c in sales_train_validation.columns if c.find('d_')==0]])\n",
    "for i in tqdm(range(len(sales_train_validation))):\n",
    "    non_zero_historical_mean.append(round(calc_non_zero_mean(historical_arr[i, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 78.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm(range(1, 29)):\n",
    "    sales_train_validation['f_1_'+str(1885+d)] = list(complete_historical_mean)\n",
    "    sales_train_validation['f_2_'+str(1885+d)] = non_zero_historical_mean\n",
    "\n",
    "method_dict[1] = \"complete historical mean\"\n",
    "method_dict[2] = \"non zero historical mean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean of # recent days (10, 20, 30, 40, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_mean_10_days = sales_train_validation[[c for c in sales_train_validation.columns if c.find('d_') == 0 and int(c.split('_')[1]) in range(1876, 1886)]].mean(axis=1).round().to_list()\n",
    "historical_mean_20_days = sales_train_validation[[c for c in sales_train_validation.columns if c.find('d_') == 0 and int(c.split('_')[1]) in range(1866, 1886)]].mean(axis=1).round().to_list()\n",
    "historical_mean_30_days = sales_train_validation[[c for c in sales_train_validation.columns if c.find('d_') == 0 and int(c.split('_')[1]) in range(1856, 1886)]].mean(axis=1).round().to_list()\n",
    "historical_mean_40_days = sales_train_validation[[c for c in sales_train_validation.columns if c.find('d_') == 0 and int(c.split('_')[1]) in range(1846, 1886)]].mean(axis=1).round().to_list()\n",
    "historical_mean_50_days = sales_train_validation[[c for c in sales_train_validation.columns if c.find('d_') == 0 and int(c.split('_')[1]) in range(1836, 1886)]].mean(axis=1).round().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 14/28 [00:00<00:00, 63.50it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      " 75%|███████▌  | 21/28 [00:00<00:00, 59.14it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      " 96%|█████████▋| 27/28 [00:00<00:00, 58.08it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\2308148260.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
      "100%|██████████| 28/28 [00:00<00:00, 58.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm(range(1, 29)):\n",
    "    sales_train_validation['f_3_' + str(1885+d)] = historical_mean_10_days\n",
    "    sales_train_validation['f_4_' + str(1885+d)] = historical_mean_20_days\n",
    "    sales_train_validation['f_5_' + str(1885+d)] = historical_mean_30_days\n",
    "    sales_train_validation['f_6_' + str(1885+d)] = historical_mean_40_days\n",
    "    sales_train_validation['f_7_' + str(1885+d)] = historical_mean_50_days\n",
    "\n",
    "method_dict[3] = \"historical mean of last 10 days\"\n",
    "method_dict[4] = \"historical mean of last 20 days\"\n",
    "method_dict[5] = \"historical mean of last 30 days\"\n",
    "method_dict[6] = \"historical mean of last 40 days\"\n",
    "method_dict[7] = \"historical mean of last 50 days\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same as previous 28 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      " 36%|███▌      | 10/28 [00:00<00:01, 11.21it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      " 64%|██████▍   | 18/28 [00:00<00:00, 20.66it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\3233770312.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
      "100%|██████████| 28/28 [00:01<00:00, 26.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm(range(1, 29)):\n",
    "    sales_train_validation['f_8_'+ str(1885+d)] = sales_train_validation['d_' + str(1885 + d - 28)].to_list()\n",
    "method_dict[8] = \"same as previous 28 days\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Infer forecast, ground truth values, and weights for all the higher level series by aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = pd.DataFrame(sales_train_validation[[c for c in sales_train_validation.columns if c.find('d_')==0 or c.find('f_')==0]].sum()).transpose() # .transpose()\n",
    "agg_df['level'] = 1\n",
    "agg_df['weight'] = 1/12\n",
    "column_order = agg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_8_1906</th>\n",
       "      <th>f_8_1907</th>\n",
       "      <th>f_8_1908</th>\n",
       "      <th>f_8_1909</th>\n",
       "      <th>f_8_1910</th>\n",
       "      <th>f_8_1911</th>\n",
       "      <th>f_8_1912</th>\n",
       "      <th>f_8_1913</th>\n",
       "      <th>level</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32631.0</td>\n",
       "      <td>31749.0</td>\n",
       "      <td>23783.0</td>\n",
       "      <td>25412.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>29211.0</td>\n",
       "      <td>28010.0</td>\n",
       "      <td>37932.0</td>\n",
       "      <td>32736.0</td>\n",
       "      <td>25572.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47825.0</td>\n",
       "      <td>37360.0</td>\n",
       "      <td>35475.0</td>\n",
       "      <td>34786.0</td>\n",
       "      <td>34003.0</td>\n",
       "      <td>45611.0</td>\n",
       "      <td>53863.0</td>\n",
       "      <td>46360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       d_1      d_2      d_3      d_4      d_5      d_6      d_7      d_8  \\\n",
       "0  32631.0  31749.0  23783.0  25412.0  19146.0  29211.0  28010.0  37932.0   \n",
       "\n",
       "       d_9     d_10  ...  f_8_1906  f_8_1907  f_8_1908  f_8_1909  f_8_1910  \\\n",
       "0  32736.0  25572.0  ...   47825.0   37360.0   35475.0   34786.0   34003.0   \n",
       "\n",
       "   f_8_1911  f_8_1912  f_8_1913  level    weight  \n",
       "0   45611.0   53863.0   46360.0      1  0.083333  \n",
       "\n",
       "[1 rows x 2167 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_groupings = {\n",
    "    2: [\"state_id\"], 3: [\"store_id\"], 4: [\"cat_id\"], 5: [\"dept_id\"], \n",
    "    6: [\"state_id\", \"cat_id\"], 7: [\"state_id\", \"dept_id\"], 8: [\"store_id\", \"cat_id\"], \n",
    "    9: [\"store_id\", \"dept_id\"], 10: [\"item_id\"], 11: [\"item_id\", \"state_id\"] # , 12: [\"item_id\", \"store_id\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 10%|█         | 1/10 [00:01<00:09,  1.03s/it]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 20%|██        | 2/10 [00:01<00:06,  1.17it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 30%|███       | 3/10 [00:02<00:05,  1.28it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 40%|████      | 4/10 [00:03<00:04,  1.34it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 50%|█████     | 5/10 [00:03<00:03,  1.31it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 60%|██████    | 6/10 [00:04<00:02,  1.35it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 70%|███████   | 7/10 [00:05<00:02,  1.38it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 80%|████████  | 8/10 [00:06<00:01,  1.41it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      " 90%|█████████ | 9/10 [00:06<00:00,  1.27it/s]C:\\Users\\923006079\\AppData\\Local\\Temp\\ipykernel_13076\\146794995.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for level in tqdm(level_groupings):\n",
    "    temp_df = sales_train_validation.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
    "    temp_df['level'] = level\n",
    "    temp_df['weight'] /= 12\n",
    "    agg_df = pd.concat([agg_df, temp_df[column_order]])\n",
    "\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation['weight'] /= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30490 12350 42840\n"
     ]
    }
   ],
   "source": [
    "print(sales_train_validation.shape[0], agg_df.shape[0], sales_train_validation.shape[0] + agg_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333334 0.9166666666666666 1.0\n"
     ]
    }
   ],
   "source": [
    "print(sales_train_validation['weight'].sum(), agg_df['weight'].sum(), sales_train_validation['weight'].sum() + agg_df['weight'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate RMSSE for All The Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series_cols = [c for c in sales_train_validation.columns if c.find(\"d_\") == 0][:-28]\n",
    "ground_truth_cols = [c for c in sales_train_validation.columns if c.find(\"d_\") == 0][-28:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 28\n",
    "n = 1885\n",
    "# rmsse need 4 data - horizon, ts for training, ts for forecast, ts, for \n",
    "def rmsse(ground_truth, forecast, train_series, axis=1):\n",
    "    assert axis==0 or axis==1\n",
    "    assert type(ground_truth) == np.ndarray or type(forecast) == np.ndarray or type(train_series) == np.ndarray\n",
    "    \n",
    "    if axis  == 1:\n",
    "        # if axis = 1 we have to make sure that data are in matrix format\n",
    "        assert ground_truth.shape[1] > 1 and forecast.shape[1] > 1 and train_series.shape[1] > 1\n",
    "    \n",
    "    numerator = ((ground_truth - forecast)**2).sum(axis=axis)\n",
    "    if axis==1:\n",
    "        denominator = 1/(n-1) * ((train_series[:, 1:] - train_series[:, :-1])**2).sum(axis=axis)\n",
    "    else:\n",
    "        denominator = 1/(n-1) * ((train_series[1:] - train_series[:-1])**2).sum(axis=axis)\n",
    "    \n",
    "    return (1/h * numerator / denominator) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all 0s\n",
      "WRMSSE 5.359792730956583 \n",
      "\n",
      "complete historical mean\n",
      "WRMSSE 1.654145319495255 \n",
      "\n",
      "non zero historical mean\n",
      "WRMSSE 4.150683531291453 \n",
      "\n",
      "historical mean of last 10 days\n",
      "WRMSSE 1.23521237018701 \n",
      "\n",
      "historical mean of last 20 days\n",
      "WRMSSE 1.2220278819228305 \n",
      "\n",
      "historical mean of last 30 days\n",
      "WRMSSE 1.1912043925125957 \n",
      "\n",
      "historical mean of last 40 days\n",
      "WRMSSE 1.205913226789875 \n",
      "\n",
      "historical mean of last 50 days\n",
      "WRMSSE 1.2018883868953785 \n",
      "\n",
      "same as previous 28 days\n",
      "WRMSSE 0.8558233199674038 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in method_dict.items():\n",
    "    sales_train_validation['rmsse'] = rmsse(\n",
    "        np.array(sales_train_validation[ground_truth_cols]),\n",
    "        np.array(sales_train_validation[[c for c in sales_train_validation.columns if c.find('f_'+str(k)) == 0]]),\n",
    "        np.array(sales_train_validation[train_series_cols])\n",
    "    )\n",
    "    agg_df[\"rmsse\"] = rmsse(\n",
    "        np.array(agg_df[ground_truth_cols]), \n",
    "        np.array(agg_df[[c for c in sales_train_validation.columns if c.find('f_'+str(k)) == 0]]), \n",
    "        np.array(agg_df[train_series_cols])\n",
    "    )\n",
    "    sales_train_validation['wrmsse'] = sales_train_validation['weight'] * sales_train_validation['rmsse']\n",
    "    agg_df['wrmsse'] = agg_df['weight'] * agg_df['rmsse']\n",
    "    print(v)\n",
    "    print(\"WRMSSE\", sales_train_validation['wrmsse'].sum() + agg_df['wrmsse'].sum(), \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
